# from langchain_core.prompts import ChatPromptTemplate
# from langchain_core.pydantic_v1 import BaseModel, Field

# # Data model
# class GradeStyleRules(BaseModel):
#     """Binary score and reasoning for the validity of style rules generated."""

#     binary_score: str = Field(description="Are the style rules reasonable and aligned with the input? Answer 'yes' or 'no'.")
#     explanation: str = Field(description="Provide reasoning for the binary score, explaining why the rules are or are not reasonable.")

# def get_structured_llm_grader(llm):
#     return llm.with_structured_output(schema=GradeStyleRules)

# def get_style_rules_grader_chain(llm):
#     structured_llm_grader = get_structured_llm_grader(llm)

#     # Prompt
#     system = """You are a grader assessing whether the style rules generated by the LLM are reasonable, aligned with the outfit request, 
#     and grounded in the context provided. You must evaluate if the style rules logically match the outfit request and seed item."""
#     style_rules_prompt = ChatPromptTemplate.from_messages(
#         [
#             ("system", system),
#             ("human", "Style Query: {style_query}\n\nGenerated Style Rules:\n\n{generation}\n\nEvaluate if these style rules align with the outfit request and seed item.")
#         ]
#     )

#     style_rules_grader_chain = style_rules_prompt | structured_llm_grader

#     return style_rules_grader_chain